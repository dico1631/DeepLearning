# Hadoop 명령어

- linux 명령어 앞에 hdfs 붙이는 형태
- linux 명령어는 내 컴퓨터에서만 작동하는데 hadoop 명령어를 쓰면 여러 개의 연결된 서버 전체를 기준으로 해당 작업을 수행 > 따라서 빅데이터에 사용



# linux 명령어

> AWS에서 사용한 명령어 모음

- sudo : 관리자 권한을 가져옴
- sudo yum install [설치할 것] : 설치하는 방법



# AWS 사용하기

> Azure도 동일 기능을 해 줌

- 일정 시간동안 입력을 안하면 연결이 끊겨서 입력이 안됨 > 창 끄기

  

- 서버(instance) 생성

  서비스 > EC2 > 인스턴스 생성 > 항목 선택 > 검토 및 시작 > 키 선택(아래 내용) > 기다렸다가 connect 하면 서버 연결

  키 생성 : 처음 키 생성할 때

  기존 키 페어 : 이미 키를 생성했을 경우

  ** 키 : 비밀번호 같은 것, 반드시 기억할 것!

  

- 서버(instance) 지우기

  서비스 > EC2 > 실행중인 인스턴스 > 작업 > 시작하기

  중지 : 중지만 됨

  종료 : 중지되고 1일만 남아있다가 아예 삭제됨

  - state가 선택한 것으로 변하면 됨

    

- 서버 만들었지만 connect가 안되는 경우 

   client가 필요하기 때문에 > Hputty와 같은 client 설치

  ** 자료실에 '**SSH-Client**' 검색



- SSH-Client 설치

  압축파일 풀기 > 실행해서 설치 완료 후 실행 > 새로 만들기 > 아래 설정하기 > 확인

  - 연결

    이름 : Tiger

    프로토콜 : SSH

    호스트 : AWS에서 만든 우분투 서버 정보에 있은 Public DNS (IPv4) 아니면 IPv4 Public IP 복사해서 붙여넣기

    포트번호 : 22

  - 사용자 인증

    방법 : Public key

    사용자 이름 : ubuntu

    사용자 키 : AWS 서버 만들 때 쓰는 key 가져오기

    

    

# docker

> 경량화 된 AWS 같은 것
>
> 가벼운 대신 버그가 많음







